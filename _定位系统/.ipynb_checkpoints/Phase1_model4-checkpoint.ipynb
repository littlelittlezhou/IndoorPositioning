{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model_4 使用svm进行的数据分类\n",
    "from sklearn import svm\n",
    "from DivisionForP2 import Dataset\n",
    "from sklearn.utils import shuffle\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from keras.utils import to_categorical\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x train: (1447, 469)\n",
      "x test: (362, 469)\n",
      "y test: (362, 3)\n",
      "original x:\n",
      " [[  0   0   0 ...   0   0   0]\n",
      " [  0   0   0 ...   0   0   0]\n",
      " [  0   0   0 ...   0   0   0]\n",
      " ...\n",
      " [  0   0   0 ...   0   0 -84]\n",
      " [  0   0   0 ...   0   0 -92]\n",
      " [  0   0   0 ...   0   0 -81]]\n",
      "all zeros to -120:\n",
      " [[-120 -120 -120 ... -120 -120 -120]\n",
      " [-120 -120 -120 ... -120 -120 -120]\n",
      " [-120 -120 -120 ... -120 -120 -120]\n",
      " ...\n",
      " [-120 -120 -120 ... -120 -120  -84]\n",
      " [-120 -120 -120 ... -120 -120  -92]\n",
      " [-120 -120 -120 ... -120 -120  -81]]\n",
      "normalized:\n",
      " [[0.         0.         0.         ... 0.         0.         0.        ]\n",
      " [0.         0.         0.         ... 0.         0.         0.        ]\n",
      " [0.         0.         0.         ... 0.         0.         0.        ]\n",
      " ...\n",
      " [0.         0.         0.         ... 0.         0.         0.50704225]\n",
      " [0.         0.         0.         ... 0.         0.         0.3943662 ]\n",
      " [0.         0.         0.         ... 0.         0.         0.54929577]]\n",
      "area mark:\n",
      " [ 7 17 20 ... 24 18 11]\n",
      "0~31:\n",
      " [ 6 16 19 ... 23 17 10]\n",
      "one hot:\n",
      " [[0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n",
      "coodix:\n",
      " [1 1 4 ... 5 4 2]\n",
      "[[0.         0.         0.         ... 0.         0.         0.68571429]\n",
      " [0.         0.         0.         ... 0.         0.87878788 0.        ]\n",
      " [0.         0.         0.         ... 0.         0.         0.47142857]\n",
      " ...\n",
      " [0.         0.         0.         ... 0.         0.         0.        ]\n",
      " [0.         0.         0.         ... 0.         0.84848485 0.        ]\n",
      " [0.         0.         0.         ... 0.         0.         0.85714286]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:475: DataConversionWarning: Data with input dtype int64 was converted to float64 by MinMaxScaler.\n",
      "  warnings.warn(msg, DataConversionWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Area correct ratio: 0.9530386740331491\n"
     ]
    }
   ],
   "source": [
    "if __name__=='__main__':\n",
    "    y_test,X_test = Dataset(\"Test_1.csv\")\n",
    "    y_train,X_train = Dataset(\"Train_1.csv\")\n",
    "\n",
    "    print(\"x train:\",np.shape(X_train))\n",
    "    print(\"x test:\",np.shape(X_test))\n",
    "    print(\"y test:\",np.shape(y_test))\n",
    "\n",
    "    # 读取数据集，数据集x每行为469个ap的读数，y为3个标签（区域，x，y）\n",
    "    ##################### 处理x\n",
    "    print(\"original x:\\n\",X_test)\n",
    "    X_train[X_train==0] = -120   # 替换其中0标记位为最低rss，暂时取-120\n",
    "    X_test[X_test==0] = -120   # 替换其中0标记位为最低rss，暂时取-120\n",
    "    print(\"all zeros to -120:\\n\",X_test)\n",
    "    # 归一化数据\n",
    "    normalize1 = MinMaxScaler()\n",
    "    normalize2 = MinMaxScaler()\n",
    "    X_train = normalize1.fit_transform(X_train)\n",
    "    X_test = normalize2.fit_transform(X_test)\n",
    "    print(\"normalized:\\n\",X_test)\n",
    "    ##################### 处理y\n",
    "    area_train = y_train[:,0] # 取出区域号\n",
    "    coodix_train = y_train[:,1]\n",
    "    coodiy_train = y_train[:,2]\n",
    "\n",
    "    area_test = y_test[:,0] # 取出区域号\n",
    "    coodix_test = y_test[:,1]\n",
    "    coodiy_test = y_test[:,2]\n",
    "    print(\"area mark:\\n\", area_train)\n",
    "    area_train = area_train -1\n",
    "    area_test = area_test -1\n",
    "    # 区域号-1以整合分类到0~31，原本是1~32\n",
    "    print(\"0~31:\\n\",area_train)\n",
    "    area_train = to_categorical(area_train,32)   # 转换为one hot\n",
    "    area_test = to_categorical(area_test,32) \n",
    "    print(\"one hot:\\n\",area_train)\n",
    "    print(\"coodix:\\n\",coodix_train)\n",
    "\n",
    "    # 由于area标签已经编码成onehot，返回来\n",
    "    area_true = np.argmax(area_test,axis=1)+1\n",
    "    area_ref = np.argmax(area_train,axis=1)+1\n",
    "    # 拆分数据集完成，样本：X_train,X_test\n",
    "    # area_train(0~31,one-hot),coodix_train,coodiy_train,area_ref(1~32)\n",
    "    # area_test(0~31,one-hot),coodix_test,coodiy_test,area_true(1~32)\n",
    "\n",
    "    \n",
    "    \n",
    "    \n",
    "    print(X_train)\n",
    "    clf = svm.SVC(C=0.8, kernel='linear',decision_function_shape='ovr')\n",
    "    clf.fit(X_train, area_ref)\n",
    "    pred_area = clf.predict(X_test)\n",
    "    \n",
    "#     pred_area = model_4_pred(X_test,X_train,y_train[:,0])\n",
    "    judge = pred_area==area_true\n",
    "    ratio = np.sum(judge!=0)/len(area_true)\n",
    "    print(\"Area correct ratio:\",ratio)\n",
    "    out = open('./Data/model_4_svm.pkl','wb')\n",
    "    pickle.dump(clf,out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
