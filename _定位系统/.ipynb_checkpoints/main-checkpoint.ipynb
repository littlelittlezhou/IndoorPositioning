{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "importing Jupyter notebook from CNN.ipynb\n",
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d (Conv2D)              (None, 20, 20, 32)        320       \n",
      "_________________________________________________________________\n",
      "max_pooling2d (MaxPooling2D) (None, 10, 10, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 8, 8, 32)          9248      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 4, 4, 32)          0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 64)                32832     \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 32)                2080      \n",
      "_________________________________________________________________\n",
      "activation (Activation)      (None, 32)                0         \n",
      "=================================================================\n",
      "Total params: 44,480\n",
      "Trainable params: 44,480\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "('Failed to import pydot. You must `pip install pydot` and install graphviz (https://graphviz.gitlab.io/download/), ', 'for `pydotprint` to work.')\n",
      "Training ------------\n",
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Download\\packet\\work\\_Aconda\\_install\\envs\\tensorflow_gpu\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py:1844: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n",
      "  warnings.warn('`Model.fit_generator` is deprecated and '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100/100 [==============================] - 5s 38ms/step - loss: 3.2977 - accuracy: 0.0881 - val_loss: 2.4069 - val_accuracy: 0.4886\n",
      "Epoch 2/50\n",
      "100/100 [==============================] - 3s 27ms/step - loss: 2.2632 - accuracy: 0.3124 - val_loss: 1.3565 - val_accuracy: 0.6989\n",
      "Epoch 3/50\n",
      "100/100 [==============================] - 3s 26ms/step - loss: 1.5725 - accuracy: 0.4664 - val_loss: 0.9184 - val_accuracy: 0.7670\n",
      "Epoch 4/50\n",
      "100/100 [==============================] - 3s 27ms/step - loss: 1.1242 - accuracy: 0.5983 - val_loss: 0.6755 - val_accuracy: 0.8097\n",
      "Epoch 5/50\n",
      " 92/100 [==========================>...] - ETA: 0s - loss: 0.8610 - accuracy: 0.6966"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-2-cfde2753b8d5>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mPhase2\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 5\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mCNN\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0marea_data_processing\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mX_data_processing\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      6\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mkeras\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Download\\packet\\work\\_Aconda\\_install\\envs\\tensorflow_gpu\\lib\\importlib\\_bootstrap.py\u001b[0m in \u001b[0;36m_find_and_load\u001b[1;34m(name, import_)\u001b[0m\n",
      "\u001b[1;32mD:\\Download\\packet\\work\\_Aconda\\_install\\envs\\tensorflow_gpu\\lib\\importlib\\_bootstrap.py\u001b[0m in \u001b[0;36m_find_and_load_unlocked\u001b[1;34m(name, import_)\u001b[0m\n",
      "\u001b[1;32mD:\\Download\\packet\\work\\_Aconda\\_install\\envs\\tensorflow_gpu\\lib\\importlib\\_bootstrap.py\u001b[0m in \u001b[0;36m_load_unlocked\u001b[1;34m(spec)\u001b[0m\n",
      "\u001b[1;32mD:\\Download\\packet\\work\\_Aconda\\_install\\envs\\tensorflow_gpu\\lib\\importlib\\_bootstrap.py\u001b[0m in \u001b[0;36m_load_backward_compatible\u001b[1;34m(spec)\u001b[0m\n",
      "\u001b[1;32m~\\code\\_定位系统\\IPYNB_IMPORTER.py\u001b[0m in \u001b[0;36mload_module\u001b[1;34m(self, fullname)\u001b[0m\n\u001b[0;32m     85\u001b[0m                     \u001b[0mcode\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshell\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minput_transformer_manager\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtransform_cell\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcell\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msource\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     86\u001b[0m                     \u001b[1;31m# run the code in themodule\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 87\u001b[1;33m                     \u001b[0mexec\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcode\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmod\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__dict__\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     88\u001b[0m         \u001b[1;32mfinally\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     89\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshell\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0muser_ns\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msave_user_ns\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\code\\_定位系统\\CNN.ipynb\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n",
      "\u001b[1;32mD:\\Download\\packet\\work\\_Aconda\\_install\\envs\\tensorflow_gpu\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit_generator\u001b[1;34m(self, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, validation_freq, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch)\u001b[0m\n\u001b[0;32m   1845\u001b[0m                   \u001b[1;34m'will be removed in a future version. '\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1846\u001b[0m                   'Please use `Model.fit`, which supports generators.')\n\u001b[1;32m-> 1847\u001b[1;33m     return self.fit(\n\u001b[0m\u001b[0;32m   1848\u001b[0m         \u001b[0mgenerator\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1849\u001b[0m         \u001b[0msteps_per_epoch\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Download\\packet\\work\\_Aconda\\_install\\envs\\tensorflow_gpu\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[0;32m   1098\u001b[0m                 _r=1):\n\u001b[0;32m   1099\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1100\u001b[1;33m               \u001b[0mtmp_logs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1101\u001b[0m               \u001b[1;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1102\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Download\\packet\\work\\_Aconda\\_install\\envs\\tensorflow_gpu\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    826\u001b[0m     \u001b[0mtracing_count\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    827\u001b[0m     \u001b[1;32mwith\u001b[0m \u001b[0mtrace\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTrace\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_name\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mtm\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 828\u001b[1;33m       \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    829\u001b[0m       \u001b[0mcompiler\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m\"xla\"\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_experimental_compile\u001b[0m \u001b[1;32melse\u001b[0m \u001b[1;34m\"nonXla\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    830\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Download\\packet\\work\\_Aconda\\_install\\envs\\tensorflow_gpu\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36m_call\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    853\u001b[0m       \u001b[1;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    854\u001b[0m       \u001b[1;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 855\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# pylint: disable=not-callable\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    856\u001b[0m     \u001b[1;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    857\u001b[0m       \u001b[1;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Download\\packet\\work\\_Aconda\\_install\\envs\\tensorflow_gpu\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   2940\u001b[0m       (graph_function,\n\u001b[0;32m   2941\u001b[0m        filtered_flat_args) = self._maybe_define_function(args, kwargs)\n\u001b[1;32m-> 2942\u001b[1;33m     return graph_function._call_flat(\n\u001b[0m\u001b[0;32m   2943\u001b[0m         filtered_flat_args, captured_inputs=graph_function.captured_inputs)  # pylint: disable=protected-access\n\u001b[0;32m   2944\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Download\\packet\\work\\_Aconda\\_install\\envs\\tensorflow_gpu\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[1;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[0;32m   1916\u001b[0m         and executing_eagerly):\n\u001b[0;32m   1917\u001b[0m       \u001b[1;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1918\u001b[1;33m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0m\u001b[0;32m   1919\u001b[0m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0;32m   1920\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n",
      "\u001b[1;32mD:\\Download\\packet\\work\\_Aconda\\_install\\envs\\tensorflow_gpu\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36mcall\u001b[1;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[0;32m    553\u001b[0m       \u001b[1;32mwith\u001b[0m \u001b[0m_InterpolateFunctionError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    554\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mcancellation_manager\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 555\u001b[1;33m           outputs = execute.execute(\n\u001b[0m\u001b[0;32m    556\u001b[0m               \u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msignature\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    557\u001b[0m               \u001b[0mnum_outputs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_num_outputs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Download\\packet\\work\\_Aconda\\_install\\envs\\tensorflow_gpu\\lib\\site-packages\\tensorflow\\python\\eager\\execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     57\u001b[0m   \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     58\u001b[0m     \u001b[0mctx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 59\u001b[1;33m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0m\u001b[0;32m     60\u001b[0m                                         inputs, attrs, num_outputs)\n\u001b[0;32m     61\u001b[0m   \u001b[1;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from DivisionForP2 import Dataset\n",
    "import IPYNB_IMPORTER\n",
    "import Phase2\n",
    "from CNN import area_data_processing,X_data_processing\n",
    "import numpy as np\n",
    "import keras\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from keras.utils import to_categorical\n",
    "from keras.models import Sequential, load_model\n",
    "from keras.layers import Dense, Activation,Dropout,Conv2D,MaxPooling2D, Flatten\n",
    "from keras.optimizers import RMSprop,Nadam,Adam\n",
    "from sklearn.model_selection import train_test_split\n",
    "import pickle\n",
    "from sklearn import svm\n",
    "from pylab import *\n",
    "from matplotlib.font_manager import FontProperties  \n",
    "import matplotlib.pyplot as plt \n",
    "# #支持中文\n",
    "# mpl.rcParams['font.sans-serif'] = ['SimHei']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 获取数据文件\n",
    "y_test,X_test = Dataset(\"Test_1.csv\")\n",
    "y_train,X_train = Dataset(\"Train_1.csv\")\n",
    "y_test_path ,x_test_path = Dataset(\"test_path.csv\") #测试路径文件\n",
    "Y_temp = np.concatenate((y_train,y_test),axis=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 统一设计一系列使用各种模型进行一阶段预测的函数，使用model_*_pred命名。\n",
    "# 在main中设计一个统筹函数pred用于调取各类model_*_pred。\n",
    "# 这种函数会读取同名的model。使用相应的预测方法进行推算。\n",
    "# 输入是预测使用的测试集x。\n",
    "# 输出是一个区域标记。这个标记用于①对比标签得到准确度，②用于阶段二计算，再进行整体评估。\n",
    "\n",
    "#使用DNN模型进行区域定位\n",
    "def model_1_pred(x):\n",
    "    model_1 = load_model(\"./Phase_1/model_1.h5\")\n",
    "    y = model_1.predict_classes(x)\n",
    "    y = y+1\n",
    "    return y\n",
    "#使用CNN模型进行区域定位\n",
    "def model_2_pred(x):\n",
    "    model_2 = load_model(\"./Phase_1/model_2.h5\")\n",
    "    y = model_2.predict_classes(x)\n",
    "    y = y+1\n",
    "    return y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 一个用于推算位置的总函数，该函数需要接受一个字符串指代模型对象，规范为\"model_*\"\n",
    "# 输入：模型名和测试样本集\n",
    "# 输出：区域号、预测（x,y）\n",
    "def pred(modelname,X_test):\n",
    "    #phase1 区域定位\n",
    "    coodix = []\n",
    "    coodiy = []\n",
    "    model = {}\n",
    "    model[\"model_1\"] = model_1_pred\n",
    "    model[\"model_2\"] = model_2_pred # 模型2来自于文件phase_1_mymodel.ipynb\n",
    "    X_test[X_test==0] = -120   # 替换其中0标记位为最低rss，暂时取-120\n",
    "    normalize = MinMaxScaler()\n",
    "    normalize.fit(X_test)\n",
    "    X_test_org = normalize.transform(X_test)\n",
    "    if modelname == \"model_2\":#在model2中输入是形状为（22，22，1）的向量\n",
    "        zero_test = np.zeros((len(X_test_org),15),dtype=float) # 生成15个全零，用于扩充训练数据（469-》484=22*22）\n",
    "        X_test = np.concatenate((X_test_org,zero_test),axis=1) # 延长每个向量到22*22\n",
    "        X_test = X_test.reshape(len(X_test),22,22)\n",
    "        X_test = np.expand_dims(X_test,axis=3)\n",
    "        area = model[modelname](X_test)\n",
    "    else:\n",
    "        area = model[modelname](X_test_org)\n",
    "    #phase2 精准定位\n",
    "    pkl_file1 = open('./Data/vaploc_1.pkl', 'rb')\n",
    "    pkl_file2 = open('./Data/rss_1m_1.pkl', 'rb')\n",
    "    vaploc = pickle.load(pkl_file1)\n",
    "    rss_1m = pickle.load(pkl_file2)\n",
    "    for index,sample in enumerate(X_test_org):\n",
    "        x,y = Phase2.SampleLoc(sample,area[index],vaploc,rss_1m,2.24)        #这里的1.6之后需要换成最优解eta,已更新：2.24\n",
    "        print(\"数据集中第\",index,\"个样本:\",x,y)\n",
    "        coodix.append(x)\n",
    "        coodiy.append(y)\n",
    "    return area,coodix,coodiy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 一个用于将（area，coox，cooy）转换为一个总坐标（x,y）的函数\n",
    "# 为此需要记录每个区域自己的坐标系原点在总坐标的位置（x_area,y_area）\n",
    "# 通过该位置记录，区域内的点坐标（x1,y1）+坐标原点在总坐标的位置（x_area,y_area）\n",
    "# = 区域内点在总坐标系中的坐标（x,y）\n",
    "# (x,y) = (coox,cooy)+ (x_area,y_area)\n",
    "def projection(area,coox,cooy):\n",
    "    # proj_coo是area原点对应到总坐标的位置，通过地形图手算\n",
    "    proj_coo = {1:(0,-35),2:(0,-30),3:(0,-25),4:(0,-20),5:(0,-15),6:(0,-10),7:(0,-5),8:(0,0),9:(0,5),10:(0,10),11:(0,15),12:(0,20),13:(0,25),14:(0,30),15:(3,-5),16:(8,-5),17:(13,-5),18:(13,0),19:(8,0),20:(3,0),21:(-5,0),22:(-11,1),23:(-16,1),24:(-21,1),25:(-26,1),26:(-31,1),27:(-36,1),28:(-41,1),29:(-46,1),30:(-51,1),31:(-56,1),32:(-61,1)}\n",
    "    x = coox + proj_coo[area][0]\n",
    "    y = cooy + proj_coo[area][1]\n",
    "    return x,y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def unique_rows(a):\n",
    "    #去掉数组重复的行\n",
    "    a = np.ascontiguousarray(a)\n",
    "    unique_a = np.unique(a.view([('', a.dtype)]*a.shape[1]))\n",
    "    return unique_a.view(a.dtype).reshape((unique_a.shape[0], a.shape[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 将所划分的区域进行构造\n",
    "def plt_coo(Y_temp):\n",
    "    coo_x = []\n",
    "    coo_y = []\n",
    "    colors = []\n",
    "    for index in range(len(Y_temp)):\n",
    "        coo_x_1,coo_y_1 = projection(Y_temp[index][0],Y_temp[index][1],Y_temp[index][2])\n",
    "        coo_x.append(coo_x_1)\n",
    "        coo_y.append(coo_y_1)\n",
    "        if Y_temp[index][0] % 2 ==0: #区域颜色区分\n",
    "            colors.append(\"b\")\n",
    "#             if Y_temp[index][0] == 2 or Y_temp[index][0] ==6 or Y_temp[index][0] ==4 or Y_temp[index][0] ==8 :\n",
    "#                 if Y_temp[index][1]!=1:\n",
    "#                     colors.append(\"b\")\n",
    "#                 else :\n",
    "#                     colors.append(\"c\")\n",
    "#             else:\n",
    "#                 if Y_temp[index][0]== 20 or Y_temp[index][0]==18:\n",
    "#                     if Y_temp[index][2]==4:\n",
    "#                         colors.append(\"b\")\n",
    "#                     else:\n",
    "#                         colors.append(\"c\")\n",
    "#                 else:\n",
    "#                     colors.append(\"c\")\n",
    "                    \n",
    "        else:\n",
    "            colors.append(\"g\")\n",
    "#             if Y_temp[index][0] ==1 or Y_temp[index][0] ==3 or Y_temp[index][0] ==5 or Y_temp[index][0] ==7:\n",
    "#                 if Y_temp[index][1]!=1:\n",
    "#                     colors.append(\"b\")\n",
    "#                 else:\n",
    "#                     colors.append(\"g\")\n",
    "#             else:\n",
    "#                 if Y_temp[index][0]== 19:\n",
    "#                     if Y_temp[index][2]==4:\n",
    "#                         colors.append(\"b\")\n",
    "#                     else:\n",
    "#                         colors.append(\"g\")\n",
    "#                 else:\n",
    "#                     colors.append(\"g\")\n",
    "\n",
    "    plt.scatter(coo_x, coo_y, s=0.5, c=colors)\n",
    "    plt.savefig(\"./Picture/project_coo.png\",dpi=120)\n",
    "    plt.show()\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_temp = unique_rows(Y_temp)\n",
    "plt_coo(Y_temp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 将划分区域的图转化为总坐标，并用散点图标注\n",
    "def data_total_coor(Y_temp):\n",
    "    coo_x = []\n",
    "    coo_y = []\n",
    "    colors = []\n",
    "    for index in range(len(Y_temp)):\n",
    "        coo_x_1,coo_y_1 = projection(Y_temp[index][0],Y_temp[index][1],Y_temp[index][2])\n",
    "        coo_x.append(coo_x_1)\n",
    "        coo_y.append(coo_y_1)\n",
    "        if Y_temp[index][0] % 2 ==0: #区域颜色区分\n",
    "            if Y_temp[index][0] == 2 or Y_temp[index][0] ==6 or Y_temp[index][0] ==4 or Y_temp[index][0] ==8 :\n",
    "                if Y_temp[index][1]!=1:\n",
    "                    colors.append(\"b\")\n",
    "                else :\n",
    "                    colors.append(\"c\")\n",
    "            else:\n",
    "                if Y_temp[index][0]== 20 or Y_temp[index][0]==18:\n",
    "                    if Y_temp[index][2]==4:\n",
    "                        colors.append(\"b\")\n",
    "                    else:\n",
    "                        colors.append(\"c\")\n",
    "                else:\n",
    "                    colors.append(\"c\")\n",
    "                    \n",
    "        else:\n",
    "            if Y_temp[index][0] ==1 or Y_temp[index][0] ==3 or Y_temp[index][0] ==5 or Y_temp[index][0] ==7:\n",
    "                if Y_temp[index][1]!=1:\n",
    "                    colors.append(\"b\")\n",
    "                else:\n",
    "                    colors.append(\"g\")\n",
    "            else:\n",
    "                if Y_temp[index][0]== 19:\n",
    "                    if Y_temp[index][2]==4:\n",
    "                        colors.append(\"b\")\n",
    "                    else:\n",
    "                        colors.append(\"g\")\n",
    "                else:\n",
    "                    colors.append(\"g\")\n",
    "\n",
    "    return coo_x,coo_y,colors\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# 一个用于评估模型效果的函数，他内部首先使用模型pred出area，coodix，coodiy\n",
    "# 随后对比这组数据和标准数据的距离\n",
    "# 输入：模型名、测试样本集、测试标签集\n",
    "# 输出：真实坐标与预测坐标的欧氏距离的平方、预测的（x,y）\n",
    "def assess(modelname,X_test,y_test):\n",
    "    pred_area,pred_x,pred_y = pred(modelname,X_test)\n",
    "    #区域准确度\n",
    "    area_true = y_test[:,0] #测试区域号的处理\n",
    "    area_true = area_data_processing(area_true)\n",
    "    area_true = np.argmax(area_true,axis=1)+1\n",
    "    coodix_test = y_test[:,1]#x,y坐标的处理\n",
    "    coodiy_test = y_test[:,2]\n",
    "    \n",
    "    judge = pred_area==area_true\n",
    "    ratio = np.sum(judge!=0)/len(area_true) #区域预测的正确率\n",
    "    print(\"Area correct ratio:\",ratio)\n",
    "    print(\"whether predict numbers = labels numbers\",len(pred_area)==len(area_true))\n",
    "    x_trues = []\n",
    "    y_trues = []\n",
    "    x_preds = []\n",
    "    y_preds = []\n",
    "    for i in range(len(area_true)):\n",
    "        print(area_true[i])\n",
    "        x_true,y_true = projection(area_true[i],coodix_test[i],coodiy_test[i])\n",
    "        x_trues.append(x_true)\n",
    "        y_trues.append(y_true)\n",
    "    for j in range(len(pred_area)):\n",
    "        x_pred,y_pred = projection(pred_area[j],pred_x[j],pred_y[j])\n",
    "        x_preds.append(x_pred)\n",
    "        y_preds.append(y_pred)\n",
    "    ds=[]\n",
    "    for k in range(len(area_true)):\n",
    "        d = Phase2.Distan(x_trues[k],y_trues[k],x_preds[k],y_preds[k])\n",
    "        ds.append(d)\n",
    "        if area_true[k]!= pred_area[k]:\n",
    "            print(\"area wrong:(ture,pred)=\",area_true[k],pred_area[k],\"in this case,d is:\",d)\n",
    "        else:\n",
    "            print(d)\n",
    "\n",
    "    return ds,x_preds,y_preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 用模型1（DNN）进行预测\n",
    "ds,x_preds,y_preds = assess(\"model_1\",X_test,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 用模型2（CNN）进行预测\n",
    "ds_2,x_preds_2,y_preds_2 = assess(\"model_2\",X_test,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "coo_x,coo_y,colors = data_total_coor(Y_temp)\n",
    "plt.scatter(coo_x, coo_y, s=0.5, c=colors)\n",
    "plt.scatter(x_preds,y_preds,s=0.5,c=\"y\",label='pred_model1')\n",
    "plt.scatter(x_preds_2,y_preds_2,s=0.5,c=\"r\",label=\"pred_model2\")\n",
    "plt.savefig(\"./Picture/pred_path.png\",dpi=120)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "\n",
    "print(\"model1_平均误差：\\n\",np.mean(ds)*0.6)\n",
    "print(\"model1_最小误差：\\n\",np.min(ds)*0.6)\n",
    "print(\"model1_最大误差：\\n\",np.max(ds)*0.6)\n",
    "\n",
    "print(\"model2_平均误差：\\n\",np.mean(ds_2)*0.6)\n",
    "print(\"model2_最小误差：\\n\",np.min(ds_2)*0.6)\n",
    "print(\"model2_最大误差：\\n\",np.max(ds_2)*0.6)\n",
    "\n",
    "#绘制MSE\n",
    "suma_1 = 0\n",
    "suma_2 = 0\n",
    "MSE_1 = []\n",
    "MSE_2 = []\n",
    "\n",
    "for j in range(len(ds)):#求均方误差\n",
    "    for i in range(j+1):\n",
    "        suma_1 += ds[i]*0.6\n",
    "        suma_2 += ds_2[i]*0.6\n",
    "    MSE_1.append(suma_1/(j+1))\n",
    "    MSE_2.append(suma_2/(j+1))\n",
    "    suma_1 = 0\n",
    "    suma_2 = 0\n",
    "l=len(MSE_1)+1\n",
    "x=np.arange(1,l)\n",
    "plt.title(\"均方误差MSE图\")\n",
    "plt.xlabel('样本个数')\n",
    "plt.ylabel('误差值')\n",
    "plt.plot(x,MSE_1,label=\"DNN\")\n",
    "plt.plot(x,MSE_2,label=\"CNN\")\n",
    "plt.legend()\n",
    "plt.savefig(\"./Picture/MSE.png\",dpi=120)\n",
    "plt.show()\n",
    "\n",
    "\n",
    "#绘制CDF\n",
    "x_cdf = np.arange(0,5,0.1) #产生0.0-5.0的数组\n",
    "y_1_cdf = []\n",
    "y_2_cdf = []\n",
    "for i in x_cdf:\n",
    "    c=np.sum(ds<=i)\n",
    "    c_2=np.sum(ds_2<=i)\n",
    "    y_1_cdf.append(c/len(ds))\n",
    "    y_2_cdf.append(c_2/len(ds))\n",
    "plt.title(\"累计分布函数CDF图\")\n",
    "plt.xlabel('误差值')\n",
    "plt.ylabel('概率')\n",
    "plt.plot(x_cdf,y_1_cdf,label=\"DNN\")\n",
    "plt.plot(x_cdf,y_2_cdf,label=\"CNN\")\n",
    "plt.legend()\n",
    "plt.savefig(\"./Picture/CDF.png\",dpi=120)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#预测路径\n",
    "# ds_path,x_preds_path,y_preds_path = assess(\"model_1\",X_test_path,y_test_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#绘制路径对比图\n",
    "# coo_x,coo_y,colors = data_total_coor(Y_temp)\n",
    "# plt.scatter(coo_x, coo_y, s=0.5, c=colors)\n",
    "# plt.scatter(x_preds_path,y_preds_path,s=0.5,c=\"y\",label='pred_path')\n",
    "# plt.savefig(\"./pred_path.png\",dpi=120)\n",
    "# plt.show()\n",
    "# plt.scatter(coo_x, coo_y, s=0.5, c=colors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
